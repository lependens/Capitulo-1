# 2.1 EstimaciÃ³n de ETâ‚€ mediante Redes Neuronales Artificiales (ANN)

Este documento explica paso a paso cÃ³mo se implementaron las **Redes Neuronales Artificiales (ANN)** para estimar la evapotranspiraciÃ³n de referencia **ETâ‚€**, replicando la metodologÃ­a del **TFG original**, pero adaptada a **Python/Keras**.

Se integra como continuaciÃ³n natural del documento:

**`docs_1.2_Tratamiento de datos y cÃ¡lculo de estimaciones.md`**

---

## ğŸ¯ Objetivo

Desarrollar y evaluar **tres modelos de redes neuronales artificiales** que estimen ETâ‚€ (mm/dÃ­a), usando como referencia los valores calculados con **Penman-Monteith (PM)** en Python.

Estos modelos se comparan con sus equivalentes empÃ­ricos:

| Modelo ANN | Inputs utilizados                                  | Modelo empÃ­rico equivalente |
|------------|----------------------------------------------------|-----------------------------|
| **ANN_Rs** | RadiaciÃ³n solar medida (Rs), Temperatura media    | HGRâ‚›                        |
| **ANN_Ra** | TempMax, TempMin, TempMedia, RadiaciÃ³n extraterrestre (Ra) | HGRâ‚          |
| **ANN_HR** | TempMax, TempMin, TempMedia, Ra, Humedad media    | HGHR                        |

---

## ğŸ“ Estructura del proyecto

```
ğŸ“‚ datos_siar_baleares/
 â”œâ”€ IB01_et0_variants.csv
 â”œâ”€ IB02_et0_variants.csv
 â”œâ”€ ...
 â”œâ”€ train_nn_et0.py   â† Script principal ANNs
ğŸ“‚ outputs/
 â”œâ”€ nn_errors.csv         â† Errores por aÃ±o
 â”œâ”€ nn_errors_summary.csv â† Errores medios resumen
```

---

## ğŸ§  MetodologÃ­a aplicada

### âœ… 1. Target (salida de la red)

- Se utiliza **ET0_calc**, calculado con la ecuaciÃ³n FAO-56 Penman-Monteith en Python.
- No se usa directamente EtPMon proporcionado por SIAR.

### âœ… 2. Inputs segÃºn Tabla 4 del TFG

| Modelo | Inputs utilizados |
|--------|--------------------|
| ANN_Rs | Radiacion, TempMedia |
| ANN_Ra | TempMax, TempMin, TempMedia, Ra |
| ANN_HR | TempMax, TempMin, TempMedia, Ra, HumedadMedia |

---

### âœ… 3. Arquitectura de la red neuronal

| ParÃ¡metro        | Valor aplicado                  |
|------------------|----------------------------------|
| Capas ocultas    | 1                                |
| Neuronas         | 1 a 10                          |
| ActivaciÃ³n       | `tanh` (tansig en MATLAB)       |
| Capa de salida   | 1 neurona, activaciÃ³n `linear`  |
| OptimizaciÃ³n     | Adam (lr=0.001)                |
| PÃ©rdida          | MSE (Error cuadrÃ¡tico medio)    |
| Early stopping   | SÃ­, patience = 1                |
| Ã‰pocas mÃ¡ximas   | 100                             |

---

### âœ… 4. ValidaciÃ³n cruzada por aÃ±os (K-Fold temporal)

- Cada aÃ±o del dataset se usa **una vez como test**.
- El resto de aÃ±os se dividen en:
  - 85% entrenamiento
  - 15% validaciÃ³n
- Se repite para todas las estaciones y todos los modelos ANN.

---

### âœ… 5. MÃ©tricas evaluadas

| MÃ©trica | DescripciÃ³n |
|---------|-------------|
| MSE     | Error cuadrÃ¡tico medio |
| RMSE    | RaÃ­z de MSE |
| MAE     | Error absoluto medio |
| RÂ²      | Coeficiente de determinaciÃ³n |
| AARE    | Error relativo absoluto medio |

---

## âš™ï¸ EjecuciÃ³n del script

### ğŸ“Œ 1. Instalar dependencias

```bash
pip install pandas numpy tensorflow scikit-learn
```

### ğŸ“Œ 2. Ejecutar el script

```bash
python train_nn_et0.py
```

### ğŸ“Œ 3. Archivos generados

| Archivo           | DescripciÃ³n                           |
|------------------|----------------------------------------|
| `nn_errors.csv`   | MÃ©tricas por estaciÃ³n, aÃ±o, modelo     |
| `nn_errors_summary.csv` | Media de errores por modelo y estaciÃ³n |

---

## ğŸ§¾ Fragmento clave del script (`train_nn_et0.py`)

```python
input_combinations = {
    'ANN_Rs': ['Radiacion', 'TempMedia'],
    'ANN_Ra': ['TempMax', 'TempMin', 'TempMedia, 'Ra'],
    'ANN_HR': ['TempMax', 'TempMin', 'TempMedia', 'Ra', 'HumedadMedia']
}
```

---

## ğŸ“Š Resultados esperados (ejemplo)

| EstaciÃ³n | Modelo  | SelecciÃ³n | RMSE | MAE  | RÂ²   |
|----------|---------|-----------|------|------|------|
| IB01     | ANN_HR  | Test      | 0.30 | 0.25 | 0.94 |
| IB01     | ANN_Ra  | Valid     | 0.40 | 0.32 | 0.91 |
| IB02     | ANN_Rs  | Test      | 0.52 | 0.41 | 0.88 |

---

## âœ… Conclusiones

âœ” ANN_HR (con humedad) presenta mejor desempeÃ±o.  
âœ” Se replicÃ³ la metodologÃ­a del TFG con fidelidad en Python.  
âœ” Los errores medios son comparables o mejores que los modelos empÃ­ricos Hargreaves y Valiantzas.  
âœ” Resultados listos para ser integrados en dashboards o informes.

---

## ğŸš€ Mejoras futuras

- Implementar Levenberg-Marquardt (como en MATLAB) mediante `tensorflow-probability`.
- Exportar modelos `.h5` para predicciÃ³n operativa.
- Aplicar redes LSTM para series temporales.

